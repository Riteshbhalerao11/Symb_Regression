{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488ad10-95a2-4797-bba2-6ebd81f5eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from transformers import  AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f860a-a3ff-44ee-b3bb-074365eac529",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Load tokenizer & model\n",
    "\n",
    "device = 'cuda'\n",
    "ckp_path = \"./bert_ckp\" # path where pretrained model & tokenizer are saved\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(ckp_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(ckp_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc72291-1ad3-471b-a5e9-343906c2d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df =  pd.read_csv(\"Data/FeynmanEquations.csv\")[['Filename','Formula']]\n",
    "data_directory = 'Data/Feynman_with_units'\n",
    "N = 20000\n",
    "# Create an empty list to store tuples of (key, value)\n",
    "data = []\n",
    "\n",
    "# Iterate over files\n",
    "for filename in os.listdir(data_directory):\n",
    "    if os.path.isfile(os.path.join(data_directory, filename)):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            # Append tuples of (key, value) for each line in the file\n",
    "            for line in lines[:N]:\n",
    "                data.append((filename, line))\n",
    "\n",
    "# Convert the list of tuples to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Filename', 'features'])\n",
    "del data\n",
    "\n",
    "df = pd.merge(eq_df,df,on=\"Filename\",how='inner').drop(columns=['Filename'])\n",
    "df = df.sample(n=300)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "def pre_tokenize(data):\n",
    "    return data.replace(\" \", ';').replace(\"\", \" \").replace(\" ; \", tokenizer.sep_token)\n",
    "\n",
    "df['features'] = df['features'].apply(pre_tokenize)\n",
    "\n",
    "test_data = Dataset.from_pandas(df)\n",
    "\n",
    "del eq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ad8ef-1a84-4921-8118-3f95536fa028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eqns(batch):\n",
    "\n",
    "    inputs = tokenizer(batch[\"features\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7f127-ce3e-4da1-a603-745e6482e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_data.map(generate_eqns, batched=True, batch_size=32, remove_columns=[\"features\"])\n",
    "\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"Formula\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37dd0b-45a3-4ab5-abb7-94de0f11ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sequence accuracy\n",
    "\n",
    "count = 0\n",
    "acc = 0\n",
    "pbar = tqdm(range(len(results)))\n",
    "pbar.set_description(\"Seq_Acc_Cal\")\n",
    "for i in pbar:\n",
    "    if pred_str[i].replace(\" \", \"\") == label_str[i].lower().strip():\n",
    "        count += 1\n",
    "    pbar.set_postfix(seq_accuracy=count / (i + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ritesh-kernel",
   "language": "python",
   "name": "ritesh-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

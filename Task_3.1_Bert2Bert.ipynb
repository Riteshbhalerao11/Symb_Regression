{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5038874-f6a1-4ba5-9921-039386c162ec",
   "metadata": {
    "id": "d5038874-f6a1-4ba5-9921-039386c162ec"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, GenerationConfig, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c29961-c128-4489-a682-f0f4cbeade42",
   "metadata": {
    "id": "86c29961-c128-4489-a682-f0f4cbeade42"
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a77a22-b79d-411c-9c8e-64dea1e08f09",
   "metadata": {
    "id": "75a77a22-b79d-411c-9c8e-64dea1e08f09"
   },
   "outputs": [],
   "source": [
    "eq_df =  pd.read_csv(\"Data/FeynmanEquations.csv\")[['Filename','Formula']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd06b21-a99d-4bda-acc6-ef0797297cad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afd06b21-a99d-4bda-acc6-ef0797297cad",
    "outputId": "1b9883bb-14e4-408d-e0e5-0d8df410fdad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_directory = 'Data/Feynman_with_units'\n",
    "N = 1000\n",
    "# Create an empty list to store tuples of (key, value)\n",
    "data = []\n",
    "\n",
    "# Iterate over files\n",
    "for filename in os.listdir(data_directory):\n",
    "    if os.path.isfile(os.path.join(data_directory, filename)):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            # Append tuples of (key, value) for each line in the file\n",
    "            for line in lines[:N]:\n",
    "                data.append((filename, line))\n",
    "\n",
    "# Convert the list of tuples to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Filename', 'features'])\n",
    "del data\n",
    "# Display DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TY_ApC7wzEF_",
   "metadata": {
    "id": "TY_ApC7wzEF_"
   },
   "outputs": [],
   "source": [
    "corpus = eq_df.Formula.tolist() + [str(i) for i in range(10)] + [\"-\", \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IFMVvTTwzE4I",
   "metadata": {
    "id": "IFMVvTTwzE4I"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = tokenizer.train_new_from_iterator(corpus, 1000)\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "tokenizer.eos_token = tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ajocXNsBzv8d",
   "metadata": {
    "id": "ajocXNsBzv8d"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461de3ed-878b-48f9-9a83-ee43533863eb",
   "metadata": {
    "id": "461de3ed-878b-48f9-9a83-ee43533863eb"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(eq_df,df,on=\"Filename\",how='inner').drop(columns=['Filename'])\n",
    "del eq_df, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9705149-9dd9-49d0-801d-828a7e52e675",
   "metadata": {
    "id": "e9705149-9dd9-49d0-801d-828a7e52e675"
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_valid = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    dat = df.iloc[i*N : N*(i+1)].sample(frac=1,random_state=SEED)\n",
    "    total_len = len(dat)\n",
    "    train_len = int(0.9 * total_len)\n",
    "    test_len = int(0.05 * total_len)  # Remaining 5% for test and valid splits\n",
    "    valid_len = total_len - train_len - test_len\n",
    "    df_train = pd.concat([df_train,dat.iloc[:train_len]])\n",
    "    df_test = pd.concat([df_test,dat.iloc[train_len:train_len + test_len]])\n",
    "    df_valid = pd.concat([df_valid, dat.iloc[train_len + test_len:]])\n",
    "\n",
    "del dat\n",
    "\n",
    "# Assign data to splits\n",
    "df_train.reset_index(inplace=True,drop=True)\n",
    "df_test.reset_index(inplace=True,drop=True)\n",
    "df_valid.reset_index(inplace=True,drop=True)\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "valid_dataset = Dataset.from_pandas(df_valid)\n",
    "\n",
    "del df_train, df_test, df_valid, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c8a12-5e73-4e04-9e5a-d482a0ba89a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba5c8a12-5e73-4e04-9e5a-d482a0ba89a1",
    "outputId": "859a4ccc-a5f6-4995-a7f8-c1aa2a695fdf"
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116a219-452d-4950-8fae-ed90b5f7b3c1",
   "metadata": {
    "id": "f116a219-452d-4950-8fae-ed90b5f7b3c1"
   },
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = tokenizer(\n",
    "        batch[\"features\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        batch[\"Formula\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "    \n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    \n",
    "    batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36013e4-8f64-4fd0-a017-e78ebfd891f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "f36013e4-8f64-4fd0-a017-e78ebfd891f9",
    "outputId": "d4ceb9bd-2d22-4c4f-a702-968130330332"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=16,\n",
    "    remove_columns=[\"Formula\", 'features'],\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=[\"Formula\", 'features'],\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=[\"Formula\", 'features'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397fe0d-4c2d-409d-a1b2-40d92f7d155c",
   "metadata": {
    "id": "4397fe0d-4c2d-409d-a1b2-40d92f7d155c"
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")\n",
    "valid_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\",  \"labels\"],\n",
    ")\n",
    "test_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\",  \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65904087-90d0-4c50-b685-52b59bbf42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
    "\n",
    "config_encoder = BertConfig()\n",
    "config_decoder = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5994f0-c4ec-4c0d-a1c0-2919c7970912",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_encoder.num_hidden_layers = 3\n",
    "config_decoder.num_hidden_layers = 12\n",
    "\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
    "bert2bert = EncoderDecoderModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nefq2Uiq4hFN",
   "metadata": {
    "id": "Nefq2Uiq4hFN"
   },
   "outputs": [],
   "source": [
    "# from transformers import EncoderDecoderModel\n",
    "\n",
    "# bert2bert = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341abd82-8dbe-40d1-802c-f50f65a8c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert2bert.config.decoder.vocab_size = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca5dc1-0dab-43b8-b95b-f3c91df068a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "bert2bert.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "bert2bert.config.eos_token_id = tokenizer.eos_token_id\n",
    "bert2bert.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "bert2bert.config.vocab_size = bert2bert.config.decoder.vocab_size\n",
    "bert2bert.config.max_length = 30\n",
    "bert2bert.config.min_length = 0\n",
    "bert2bert.config.no_repeat_ngram_size = 0\n",
    "bert2bert.config.early_stopping = False\n",
    "bert2bert.config.length_penalty = 1.0\n",
    "bert2bert.config.num_beams = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731631b9-4ea3-4a31-9e78-3021b35601fe",
   "metadata": {
    "id": "731631b9-4ea3-4a31-9e78-3021b35601fe"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    count = 0\n",
    "    total =  len(pred_str)\n",
    "    for i in range(total):\n",
    "      if(pred_str[i] == label_str[i]):\n",
    "        count+=1\n",
    "    acc = count / total\n",
    "\n",
    "    return {\"sequence_accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0bd177-5684-4314-a19f-0ba1ebd0bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = math.ceil(len(train_dataset) / 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45967455-cf54-4b8b-8514-f74413b82731",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "45967455-cf54-4b8b-8514-f74413b82731",
    "outputId": "fb8c41f0-7983-4556-c1d5-b64d77286dad"
   },
   "outputs": [],
   "source": [
    "trainer_args = Seq2SeqTrainingArguments(output_dir=\"./bert_3_gredy\",\n",
    "                                          fp16=True, # # Change to False if using CPU only\n",
    "                                          predict_with_generate = True,\n",
    "                                          learning_rate=0.0001 ,\n",
    "                                          num_train_epochs=100, # The total number of training epochs to run.\n",
    "                                          per_device_train_batch_size=16,  # batch size per device during training\n",
    "                                          per_device_eval_batch_size=32, # batch size for evaluation\n",
    "                                          # gradient_accumulation_steps=2,\n",
    "                                          report_to=\"none\",\n",
    "                                          evaluation_strategy=\"steps\", # Evaluated at the end of epochs\n",
    "                                          eval_steps=steps,\n",
    "                                          do_eval=True,\n",
    "                                          save_strategy=\"steps\",\n",
    "                                          save_steps= steps,\n",
    "                                          save_total_limit=2, # Save the best and most recent checkpoints\n",
    "                                          logging_strategy='steps',\n",
    "                                          logging_steps=steps,\n",
    "                                          load_best_model_at_end=True, # Load the best model at the end\n",
    "                                          metric_for_best_model=\"sequence_accuracy\",\n",
    "                                          greater_is_better=True,\n",
    "                                          save_safetensors=False\n",
    "            \n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ab55a-d2f6-4395-8e63-08ddfa8dce5d",
   "metadata": {
    "id": "012ab55a-d2f6-4395-8e63-08ddfa8dce5d",
    "outputId": "b2df564c-5c57-4897-e29f-ffea83594d0b"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=bert2bert,\n",
    "    tokenizer=tokenizer,\n",
    "    args=trainer_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82abac7-1391-45ec-838f-2a18a7ff3557",
   "metadata": {
    "id": "c82abac7-1391-45ec-838f-2a18a7ff3557",
    "outputId": "e72596de-e5c8-46a8-98c9-091b1f9aee44"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Ritesh-kernel",
   "language": "python",
   "name": "ritesh-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
